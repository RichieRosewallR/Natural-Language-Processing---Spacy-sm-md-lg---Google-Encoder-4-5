{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU8by2vX8CaA"
   },
   "source": [
    "Welcome!\n",
    "Downloading the spacy trained model & pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekTjDNobOwk8"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMIxSRIrWvWo"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFKacrTP0EWy"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzRwBOkM8mqi"
   },
   "source": [
    "Importing Relevant Libraries Keeping a list of tags in **my_list** and searching for tags in **test**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aebt3AMKWvZn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "my_list =['Communication', 'Self-learning', 'Attitude', 'Listening Skills', 'Leadership', 'Adaptability', 'Team  Player', 'Python',  'Django', 'PostgreSQL', 'Restframe work', 'Angular', 'Cypress', 'Selenium', 'Java', 'SaaS sales experience', 'Lead generation', 'Problem solving', 'Good  Candidate']\n",
    "df = pd.DataFrame()\n",
    "df['tags'] = my_list\n",
    "test = 'speaking'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKPj4gTI9Svl"
   },
   "source": [
    "We must test which trained models are appropriate for our use cases because we are using trained models. We already know that the word **'speaking'** is directly related to the word **'communication'** We'll see which of these models produces** 'communication'** as the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvBXMDQ50-Dr"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "test_vec = nlp(test)\n",
    "all_docs =[nlp(row) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = all_docs[i].similarity(test_vec)\n",
    "  sims.append(sim)\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uVCF0Md-DdF"
   },
   "source": [
    "Our test fails when we use the model **en core web sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDhVOmwyW8X4"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "test_vec = nlp(test)\n",
    "all_docs =[nlp(row) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = all_docs[i].similarity(test_vec)\n",
    "  sims.append(sim)\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krP0bgOs-Swg"
   },
   "source": [
    "Our test is partially fulfilled by using the model **en core web md**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV-ypj-5W8ag"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "test_vec = nlp(test)\n",
    "all_docs =[nlp(row) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = all_docs[i].similarity(test_vec)\n",
    "  sims.append(sim)\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDf0mbSF-dFG"
   },
   "source": [
    "Our test is partially fulfilled by using the model **en core web lg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0n8AJjC-gML"
   },
   "source": [
    "Having gone through each **spacy** model, We didn't obtain the outcome we were hoping for. Now we'll move on to **Google** models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5zYchM_Vdk3"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "test_vec = nlp([test])\n",
    "all_docs =[nlp([row]) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = cosine_similarity(all_docs[i],test_vec)\n",
    "  sims.append(sim[0][0])\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWCFaq8_--Vz"
   },
   "source": [
    "Our test is fully satisfied by the use of **universal-sentence-encoder/4**. Observe yet another Google model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CnQ_5e43kvU"
   },
   "outputs": [],
   "source": [
    "nlp = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "test_vec = nlp([test])\n",
    "all_docs =[nlp([row]) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = cosine_similarity(all_docs[i],test_vec)\n",
    "  sims.append(sim[0][0])\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-jkbe_t_CEs"
   },
   "source": [
    "Our test fails when we use the model **universal-sentence-encoder-large/5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIKBdAYVOSzn"
   },
   "source": [
    "In conclusion, Google's **universal-sentence-encoder/4** provides the best outcome for the particular use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWox6MdWR6MA"
   },
   "source": [
    "# The finalized code appears below cell. we can search with any input.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwEqkFJuOouF"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "test_vec = nlp([input()])\n",
    "all_docs =[nlp([row]) for row in df['tags']]\n",
    "sims = []\n",
    "doc_id = []\n",
    "for i in range(len(all_docs)):\n",
    "  sim = cosine_similarity(all_docs[i],test_vec)\n",
    "  sims.append(sim[0][0])\n",
    "  doc_id.append(i)\n",
    "  sims_docs= pd.DataFrame(list(zip(doc_id, sims)), columns= ['doc_id', 'sims'])\n",
    "sims_docs_sorted =sims_docs.sort_values(by='sims', ascending=False)\n",
    "top_5=df.iloc[sims_docs_sorted['doc_id'][1:6]]\n",
    "top_5_with_score= pd.concat([top_5,sims_docs_sorted['sims'][1:6]], axis = 1)\n",
    "top_5_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y00XuHVlQIBk"
   },
   "source": [
    "The top 1 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfIC1GZwOox9"
   },
   "outputs": [],
   "source": [
    "print('similar tag is {}{}{} and corresponding similarity score is {}{:.2f}{}'.format('\\033[1m',top_5_with_score['tags'].iloc[0], '\\033[0m', '\\033[1m', top_5_with_score['sims'].iloc[0],'\\033[0m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vozeOUqfSe3y"
   },
   "source": [
    "P.S. There are lot other trained models available in the market which i have not used here. I have selected only the most popular highly rated models. we can also train from scratch and calculate similarty using  cosine similarity formula Cos(x, y) = x . y / ||x|| * ||y||. There are other methods to calculate similarities as follows, Euclidean Distance, Manhattan Distance, Jaccard Similarity, Minkowski Distance. \n",
    "\n",
    "# Thank you."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
